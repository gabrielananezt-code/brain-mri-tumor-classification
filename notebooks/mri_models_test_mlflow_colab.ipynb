{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d4265f",
   "metadata": {
    "id": "33d4265f"
   },
   "source": [
    "\n",
    "# Sistema de clasificaci√≥n de tipos de c√°ncer cerebral mediante redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae25956",
   "metadata": {
    "id": "5ae25956"
   },
   "source": [
    "## Setup para Google Colab (GPU T4) + MLflow\n",
    "\n",
    "Este notebook se ejecuta en **Google Colab** usando GPU **T4** y registrar experimentos en **MLflow**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdtvyhOuppMG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1771471383244,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "fdtvyhOuppMG",
    "outputId": "b4615aba-7e5f-4c35-afea-4312ba04b0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 19 03:23:01 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   64C    P0             30W /   70W |    1367MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             405      C   /usr/bin/python3                       1364MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9cfd48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5830,
     "status": "ok",
     "timestamp": 1771471389073,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "6e9cfd48",
    "outputId": "287b2b67-460b-44a6-b2c5-104e9d190c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU 0: Tesla T4 (UUID: GPU-0a7cdaf3-afc6-5bdf-6712-9ff655749c6b)\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "MLFLOW_TRACKING_URI: http://3.89.116.159:8050\n",
      "MLFLOW_EXPERIMENT_NAME: mri_tumor_classification_t4\n",
      "DATASET_DIR: /content/drive/MyDrive/brain-mri/data/raw/brain-tumor-mri-scans\n"
     ]
    }
   ],
   "source": [
    "# Instalar dependencias \n",
    "!pip -q install -U mlflow kagglehub torchsummary seaborn ipywidgets\n",
    "\n",
    "import os, torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi -L\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://<EC2_IP>:8050\"\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"mri_tumor_classification_t4\"\n",
    "\n",
    "# Dataset (Drive)\n",
    "os.environ[\"DATASET_DIR\"] = \"/content/drive/MyDrive/brain-mri/data/raw/brain-tumor-mri-scans\"\n",
    "\n",
    "print(\"MLFLOW_TRACKING_URI:\", os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "print(\"MLFLOW_EXPERIMENT_NAME:\", os.environ[\"MLFLOW_EXPERIMENT_NAME\"])\n",
    "print(\"DATASET_DIR:\", os.environ[\"DATASET_DIR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "py-g3IKmuKA5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1771471389106,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "py-g3IKmuKA5",
    "outputId": "867d8555-3d90-4d63-e921-f747a4b4fa19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_DIR (local): /content/brain-tumor-mri-scans\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_DS = os.environ[\"DATASET_DIR\"]\n",
    "LOCAL_DS = \"/content/brain-tumor-mri-scans\"\n",
    "\n",
    "if not Path(LOCAL_DS).exists():\n",
    "    print(\"Copiando dataset desde Drive a /content ...\")\n",
    "    shutil.copytree(DRIVE_DS, LOCAL_DS)\n",
    "\n",
    "os.environ[\"DATASET_DIR\"] = LOCAL_DS\n",
    "print(\"DATASET_DIR (local):\", os.environ[\"DATASET_DIR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "jq6CPrdFufWD",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1771471389110,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "jq6CPrdFufWD"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a009b71b",
   "metadata": {
    "id": "a009b71b"
   },
   "source": [
    "Desarrollar un m√©todo basado en redes neuronales convolucionales que permita\n",
    "clasificar con exactitud im√°genes extra√≠das de MRIs en una de las 4 categor√≠as\n",
    "\n",
    "- Glioma: Detecta masas an√≥malas con bordes irregulares y heterogeneidad en el tejido cerebral.\n",
    "- Meningioma: Identifica tumores bien delimitados originados en las meninges.\n",
    "- Pituitary: Clasifica adenomas hipofisarios en la regi√≥n selar.\n",
    "- Tejido sano: Diferencia el tejido cerebral normal sin anomal√≠as presentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399GKeb1ql9K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1771471390629,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "399GKeb1ql9K",
    "outputId": "6aed427d-6267-44cd-d068-7f412affadd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 03:23:08 INFO mlflow.tracking.fluent: Experiment with name 'mri_tumor_classification_t4' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run colab_ping at: http://3.89.116.159:8050/#/experiments/1/runs/a48b46a71d6e4239b90ce4ac4f409c9b\n",
      "üß™ View experiment at: http://3.89.116.159:8050/#/experiments/1\n",
      "‚úÖ Colab pudo loggear en MLflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "mlflow.set_experiment(os.environ[\"MLFLOW_EXPERIMENT_NAME\"])\n",
    "\n",
    "with mlflow.start_run(run_name=\"colab_ping\"):\n",
    "    mlflow.log_param(\"ping\", 1)\n",
    "\n",
    "print(\"Colab pudo loggear en MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a03236b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10693,
     "status": "ok",
     "timestamp": 1771471401323,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "a03236b4",
    "outputId": "7f43af31-3b25-4064-cbe0-0e73a8222c02",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
      "Requirement already satisfied: kagglesdk<1.0,>=0.1.14 in /usr/local/lib/python3.12/dist-packages (from kagglehub) (0.1.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kagglesdk<1.0,>=0.1.14->kagglehub) (5.29.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2579ab89",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1771471401361,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "2579ab89"
   },
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import random\n",
    "import kagglehub\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7214ff08",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1771471401362,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "7214ff08"
   },
   "outputs": [],
   "source": [
    "# (Opcional) Instalar MLflow si no est√° instalado\n",
    "# !pip -q install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6ca99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1771471401554,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "59d6ca99",
    "outputId": "b9152f9d-646b-4545-ae48-ca92d57347dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_TRACKING_URI: http://3.89.116.159:8050\n",
      "Experiment: mri_tumor_classification_t4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# Configuraci√≥n MLflow\n",
    "# =========================\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"file:/content/mlruns\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "EXPERIMENT_NAME = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"mri_tumor_classification\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(\"MLFLOW_TRACKING_URI:\", MLFLOW_TRACKING_URI)\n",
    "print(\"Experiment:\", EXPERIMENT_NAME)\n",
    "\n",
    "ARTIFACT_DIR = Path(\"./artifacts\")\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf24ec8b",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1771471401600,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "cf24ec8b"
   },
   "outputs": [],
   "source": [
    "def _save_fig_and_log(fig, filename: str):\n",
    "    path = ARTIFACT_DIR / filename\n",
    "    fig.savefig(path, bbox_inches=\"tight\", dpi=160)\n",
    "    mlflow.log_artifact(str(path))\n",
    "    return path\n",
    "\n",
    "def log_training_curves(train_losses, val_losses, train_accs, val_accs, prefix: str):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.plot(train_losses, label=\"train_loss\")\n",
    "    ax1.plot(val_losses, label=\"val_loss\")\n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    ax1.set_ylabel(\"loss\")\n",
    "    ax1.set_title(f\"{prefix} - Loss\")\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.plot(train_accs, label=\"train_acc\")\n",
    "    ax2.plot(val_accs, label=\"val_acc\")\n",
    "    ax2.set_xlabel(\"epoch\")\n",
    "    ax2.set_ylabel(\"accuracy\")\n",
    "    ax2.set_title(f\"{prefix} - Accuracy\")\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "    _save_fig_and_log(fig, f\"{prefix}_training_curves.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def evaluate_and_log(model, dataloader, device, prefix: str, class_names=None):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    # M√©tricas globales\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        f\"{prefix}_accuracy\": float(acc),\n",
    "        f\"{prefix}_precision_w\": float(prec),\n",
    "        f\"{prefix}_recall_w\": float(rec),\n",
    "        f\"{prefix}_f1_w\": float(f1),\n",
    "    })\n",
    "\n",
    "    # Reporte de clasificaci√≥n como artefacto\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, zero_division=0)\n",
    "    report_path = ARTIFACT_DIR / f\"{prefix}_classification_report.txt\"\n",
    "    report_path.write_text(report, encoding=\"utf-8\")\n",
    "    mlflow.log_artifact(str(report_path))\n",
    "\n",
    "    # Matriz de confusi√≥n como figura\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    im = ax.imshow(cm)\n",
    "    ax.set_title(f\"{prefix} - Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    # ticks si hay nombres\n",
    "    if class_names is not None:\n",
    "        ax.set_xticks(range(len(class_names)))\n",
    "        ax.set_yticks(range(len(class_names)))\n",
    "        ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(class_names)\n",
    "\n",
    "    # anotar valores\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "    _save_fig_and_log(fig, f\"{prefix}_confusion_matrix.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Guardar m√©tricas en JSON\n",
    "    metrics_path = ARTIFACT_DIR / f\"{prefix}_eval_metrics.json\"\n",
    "    metrics_path.write_text(json.dumps({\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision_weighted\": float(prec),\n",
    "        \"recall_weighted\": float(rec),\n",
    "        \"f1_weighted\": float(f1),\n",
    "    }, indent=2), encoding=\"utf-8\")\n",
    "    mlflow.log_artifact(str(metrics_path))\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1c168e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1771471403014,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "a1c168e4",
    "outputId": "de58dee8-00ea-492d-d4d0-9a3c908f45e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'brain-tumor-mri-scans' dataset.\n",
      "Path to dataset files: /kaggle/input/brain-tumor-mri-scans\n"
     ]
    }
   ],
   "source": [
    "# Descargar el enlace del Dataset\n",
    "path = kagglehub.dataset_download(\"rm1000/brain-tumor-mri-scans\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0f7b9ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1771471403037,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "e0f7b9ec",
    "outputId": "90b72745-6923-4004-ae6e-6124797e1890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificar que se est√© trabajando con GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243a6ff",
   "metadata": {
    "id": "5243a6ff"
   },
   "source": [
    "### 1. Preprocesamiento de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314db631",
   "metadata": {
    "id": "314db631"
   },
   "source": [
    "### 1.1 Par√°metros para el preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8f106",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1771471403048,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "91d8f106",
    "outputId": "8ae324dd-0dbb-4a5a-ede1-78e4e26b7d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /content/brain-tumor-mri-scans\n",
      "{'img_size': 180, 'batch_size': 32, 'val_split': 0.2, 'seed': 42}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import torch\n",
    "\n",
    "# =========================\n",
    "# Configuraci√≥n de datos / hiperpar√°metros\n",
    "# =========================\n",
    "DATASET_SLUG = \"rm1000/brain-tumor-mri-scans\"\n",
    "dataset_path = os.getenv(\"DATASET_DIR\")\n",
    "\n",
    "if not dataset_path:\n",
    "    print(f\"DATASET_DIR no definido. Descargando con kagglehub: {DATASET_SLUG}\")\n",
    "    dataset_path = kagglehub.dataset_download(DATASET_SLUG)\n",
    "\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "\n",
    "# Tama√±o de las im√°genes \n",
    "img_size = int(os.getenv(\"IMG_SIZE\", \"180\"))\n",
    "\n",
    "# Tama√±o de batch \n",
    "batch_size = int(os.getenv(\"BATCH_SIZE\", \"32\"))\n",
    "\n",
    "# Porcentaje de datos para validaci√≥n \n",
    "val_split = float(os.getenv(\"VAL_SPLIT\", \"0.2\"))\n",
    "\n",
    "# Semilla \n",
    "seed = int(os.getenv(\"SEED\", \"42\"))\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print({\"img_size\": img_size, \"batch_size\": batch_size, \"val_split\": val_split, \"seed\": seed})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46212c7",
   "metadata": {
    "id": "c46212c7"
   },
   "source": [
    "### 1.2 Pipeline de preprocesamiento\n",
    "\n",
    "A continuacion se screa el pipeline de preprocesamiento de images, el cual realiza los siguientes pasos:\n",
    "* redimensiona la imagen a 180x180\n",
    "* se Convierte la imagen para que tenga un solo canal en escala de grices.\n",
    "* se aplica normalizacion a los datos para que queden en el rando de [-1, 1]\n",
    "------\n",
    "Para el conjunto de datos de entrenamiento, se decide aplicar, adem√°s de los pasos previos, t√©cnicas de aumento de datos (data augmentation) para enriquecer la variedad de ejemplos y mejorar la generalizaci√≥n del modelo.\n",
    "* se  refleja la imagen de izquierda a derecha.\n",
    "* se rota la imagen de manera aleatoria entre -15 y 15 grados.\n",
    "* se ajusta aleatoriamente el brillo y el contraste de la imagen dentro de un rango de 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fe8736b",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1771471403051,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "8fe8736b"
   },
   "outputs": [],
   "source": [
    "# Pipeline de preparaci√≥n de im√°genes (Proprocesamiento)\n",
    "\n",
    "# Transformaciones para el conjunto de entrenamiento con data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    # Redimensiona la imagen para que todas tengan un tama√±o fijo\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    # Convierte las im√°genes a escalas de grises para tener 1 solo canal\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "\n",
    "    ###### inicio data augmentation en train #######\n",
    "    # Reflejar de forma horizontal la imagen\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Rotaciones aleatorias de la im√°gen entre -15 y 15 grados\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    # Desplaza horizontal y verticalmente las im√°genes\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    # Variaci√≥n de brillo y contraste, simula variaciones en el brillo y contraste\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    ###### fin data augmentation en train #######\n",
    "\n",
    "    # Convierte im√°genes en tensores de [0,255] a [0,1]\n",
    "    transforms.ToTensor(),\n",
    "    # Centrar alrededor de 0 con un rango aproximado de [-1,1]\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Transformaciones para el conjunto de validaci√≥n\n",
    "val_transform = transforms.Compose([\n",
    "    # Redimensiona la imagen para que todas tengan un tama√±o fijo\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    # Convierte las im√°genes a escalas de grises para tener 1 solo canal y no 3 duplicados\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    # Convierte im√°genes en tensores de [0,255] a [0,1]\n",
    "    transforms.ToTensor(),\n",
    "    # Centrar alrededor de 0 con un rango aproximado de [-1,1]\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df50412",
   "metadata": {
    "id": "6df50412"
   },
   "source": [
    "### 2. Division del dataset\n",
    "\n",
    "El dataset se divide en datos de train y val. Adicional, se aplica el pipeline de preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b11d7009",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1771471403120,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "b11d7009"
   },
   "outputs": [],
   "source": [
    "# --- Recomendaci√≥n Colab ---\n",
    "# 2‚Äì4 workers suele ser el punto dulce. Empieza con 2.\n",
    "num_workers = int(os.getenv(\"NUM_WORKERS\", 2))\n",
    "\n",
    "# pin_memory acelera la transferencia CPU->GPU\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "# prefetch_factor solo aplica si num_workers>0\n",
    "prefetch_factor = 2 if num_workers > 0 else None\n",
    "\n",
    "# =========================\n",
    "# Dataset + split\n",
    "# =========================\n",
    "dataset = datasets.ImageFolder(root=dataset_path)\n",
    "labels = [item[1] for item in dataset.samples]\n",
    "\n",
    "Stratified = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=seed)\n",
    "train_index, val_index = next(Stratified.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "train_dataset = ImageFolder(root=dataset_path, transform=train_transform)\n",
    "val_dataset   = ImageFolder(root=dataset_path, transform=val_transform)\n",
    "\n",
    "train_db = torch.utils.data.Subset(train_dataset, train_index)\n",
    "val_db   = torch.utils.data.Subset(val_dataset, val_index)\n",
    "\n",
    "# =========================\n",
    "# DataLoaders optimizados\n",
    "# =========================\n",
    "train_data_load = DataLoader(\n",
    "    train_db,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=(num_workers > 0),\n",
    "    prefetch_factor=prefetch_factor if prefetch_factor is not None else 2,\n",
    "    drop_last=True,  # mejora rendimiento y estabilidad de batch\n",
    ")\n",
    "\n",
    "val_data_load = DataLoader(\n",
    "    val_db,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=(num_workers > 0),\n",
    "    prefetch_factor=prefetch_factor if prefetch_factor is not None else 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d794a6",
   "metadata": {
    "id": "08d794a6"
   },
   "source": [
    "Se obtiene la ditribuccion de las clases para el dataset completo y tambien para las divisiones previas que se realizaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6be0b0e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1771471403288,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "6be0b0e6",
    "outputId": "8c510865-5af7-4359-b115-4fae9b6b2c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset completo\n",
      "Etiqueta: glioma, Cantidad de im√°genes: 1621\n",
      "Etiqueta: healthy, Cantidad de im√°genes: 2000\n",
      "Etiqueta: meningioma, Cantidad de im√°genes: 1645\n",
      "Etiqueta: pituitary, Cantidad de im√°genes: 1757\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset de Entrenamiento\n",
      "Etiqueta: healthy, Cantidad de im√°genes: 1600\n",
      "Etiqueta: pituitary, Cantidad de im√°genes: 1405\n",
      "Etiqueta: meningioma, Cantidad de im√°genes: 1316\n",
      "Etiqueta: glioma, Cantidad de im√°genes: 1297\n",
      "\n",
      "Dataset de Validaci√≥n\n",
      "Etiqueta: healthy, Cantidad de im√°genes: 400\n",
      "Etiqueta: glioma, Cantidad de im√°genes: 324\n",
      "Etiqueta: pituitary, Cantidad de im√°genes: 352\n",
      "Etiqueta: meningioma, Cantidad de im√°genes: 329\n"
     ]
    }
   ],
   "source": [
    "# Imprimir la cantidad de im√°genes por cada categor√≠a (Clase)\n",
    "class_counts = Counter(labels)\n",
    "print(\"\\nDataset completo\")\n",
    "for class_idx, count in class_counts.items():\n",
    "    # Obtener el nombre de la clase a partir del √≠ndice\n",
    "    class_name = dataset.classes[class_idx]\n",
    "    print(f\"Etiqueta: {class_name}, Cantidad de im√°genes: {count}\")\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar([dataset.classes[class_idx] for class_idx in class_counts.keys()], list(class_counts.values()), color='skyblue')\n",
    "plt.xlabel('Clases')\n",
    "plt.ylabel('Cantidad de im√°genes')\n",
    "plt.title('Distribuccion de las clases en dataset completo')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Para el dataset de entrenamiento\n",
    "train_labels = [dataset.samples[i][1] for i in train_db.indices]\n",
    "train_class_counts = Counter(train_labels)\n",
    "\n",
    "# Para el dataset de validaci√≥n\n",
    "val_labels = [dataset.samples[i][1] for i in val_db.indices]\n",
    "val_class_counts = Counter(val_labels)\n",
    "\n",
    "# Imprimir resultados del set de entrenamiento\n",
    "print(\"\\nDataset de Entrenamiento\")\n",
    "for class_idx, count in train_class_counts.items():\n",
    "    class_name = dataset.classes[class_idx]\n",
    "    print(f\"Etiqueta: {class_name}, Cantidad de im√°genes: {count}\")\n",
    "\n",
    "# Imprimir resultados del set de validaci√≥n\n",
    "print(\"\\nDataset de Validaci√≥n\")\n",
    "for class_idx, count in val_class_counts.items():\n",
    "    class_name = dataset.classes[class_idx]\n",
    "    print(f\"Etiqueta: {class_name}, Cantidad de im√°genes: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92aaac2",
   "metadata": {
    "id": "e92aaac2"
   },
   "source": [
    "### 4. Funcion de entrenamiento ( train)\n",
    "\n",
    "* Coloca el modelo en modo entrenamiento (model.train()).\n",
    "* Recorre los minibatches del conjunto de entrenamiento.\n",
    "\n",
    "Para cada batch:\n",
    "\n",
    "* Reinicia los gradientes del optimizador.\n",
    "* Realiza una pasada hacia adelante.\n",
    "* Calcula la p√©rdida.\n",
    "* Realiza retropropagaci√≥n.\n",
    "* Actualiza los pesos del modelo\n",
    "* Acumula la p√©rdida total y el n√∫mero de predicciones correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "808c283d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1771471403291,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "808c283d"
   },
   "outputs": [],
   "source": [
    "# Funci√≥n de entrenamiento\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031fb5a",
   "metadata": {
    "id": "e031fb5a"
   },
   "source": [
    "### 5. Funcion de evaluacion (evaluate)\n",
    "\n",
    "* Pone el modelo en modo evaluaci√≥n (model.eval())\n",
    "* Desactiva el c√°lculo de gradientes para acelerar el proceso\n",
    "\n",
    "Recorre los batches del conjunto de validaci√≥n y:\n",
    "\n",
    "* Obtiene las predicciones y calcula la p√©rdida.\n",
    "* Acumula la p√©rdida total y la cantidad de predicciones correctas.\n",
    "* Devuelve la p√©rdida promedio y la precisi√≥n en validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74f951a2",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1771471403314,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "74f951a2"
   },
   "outputs": [],
   "source": [
    "# Funci√≥n de evaluaci√≥n\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_accuracy = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfbd41d",
   "metadata": {
    "id": "ecfbd41d"
   },
   "source": [
    "### 7. Etapa de modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283a79e",
   "metadata": {
    "id": "4283a79e"
   },
   "source": [
    "Para abordar el caso planteado, se decide probar 3 soluciones, dos de ella con arquitecturas propuestas en investigaciones relacionadas y la √∫ltima a partir de transfer learning con EfficientNetB0 de la familia de EfficientNet de Google:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df1171",
   "metadata": {
    "id": "b1df1171"
   },
   "source": [
    "### Arquitectura # 1 Red Neuronal Convolicional (CNN)\n",
    "\n",
    "Esta CNN cuenta con tres bloques:\n",
    "\n",
    "Bloque 1: Busca extraer caracter√≠sticas simples (Bordes, contornos y patrones simples):\n",
    "\n",
    "\n",
    "* Capa 1: 4 filtros, kernel 3x3 y padding=1.\n",
    "* Capa 2: 8 filtros, kernel 3x3 y padding=1.\n",
    "* Batch Normalization despu√©s de cada convoluci√≥n.\n",
    "* Maxpool: 2x2, reduce resoluci√≥n a la mitad\n",
    "\n",
    "\n",
    "Bloque 2: Busca extraer caracter√≠sticas como texturas y formas m√°s complejas:\n",
    "\n",
    "* Capa 1: 16 filtros, kernel 5x5 y padding=2.\n",
    "* Capa 2: 32 filtros, kernel 5x5 y padding=2.\n",
    "* Capa 2: 64 filtros, kernel 5x5 y padding=2.\n",
    "* Batch Normalization despu√©s de cada convoluci√≥n.\n",
    "* Maxpool: 2x2, reduce resoluci√≥n a la mitad\n",
    "\n",
    "Bloque 3: Busca extraer caracter√≠sticas m√°s profundas:\n",
    "\n",
    "* Capa 1: 128 filtros, kernel 5x5 y padding=2.\n",
    "* Capa 2: 256 filtros, kernel 5x5 y padding=2.\n",
    "* Batch Normalization despu√©s de cada convoluci√≥n.\n",
    "* AdaptiveAvgPool: Ayuda a garantizar una salida fija, necesaria para la capa densa.\n",
    "\n",
    "Bloque 4: Bloque de clasificaci√≥n (4 clases):\n",
    "\n",
    "* Flatten del tensor (1024)\n",
    "* Capa densa: Predicci√≥n de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2eb8bb35",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1771471403325,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "2eb8bb35"
   },
   "outputs": [],
   "source": [
    "class TumorMRICNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(TumorMRICNN, self).__init__()\n",
    "\n",
    "        # Est√°s capas iniciales buscan identificar caracter√≠sticas mas simples como bordes, contornos o lineas\n",
    "        # Capa convolicional 1 con entrada (1 canal) , con 4 filtros, kernel 3x3 con stride de 1 y padding para no perder los bordes\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(4)\n",
    "\n",
    "        # Capa convolicional 2 con 8 filtros, kernel 3x3 con stride de 1 y padding para no perder los bordes\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Max Pooling de 2x2 con un stride de 2 que reduce la imagen a la mitad conservando la representaci√≥n\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Est√°s capas con mayor cantidad de filtros pretenden identificar car√°cter√≠sticas mas complejas como los tumores\n",
    "        # Capa convolicional 3 con 16 filtros, kernel 5x5 con stride de 1 y padding de 2 dado que el kernel es 5x5 para no perder los bordes\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Capa convolicional 4 con 32 filtros, kernel 5x5 con stride de 1 y padding de 2 dado que el kernel es 5x5 para no perder los bordes\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Capa convolicional 5 con 64 filtros, kernel 5x5 con stride de 1 y padding de 2 dado que el kernel es 5x5 para no perder los bordes\n",
    "        self.conv5 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Max Pooling con un stride de 2 que reduce la imagen a la mitad conservando la representaci√≥n\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Capa convolicional 6 con 128 filtros, kernel 7x7 con stride de 1 y padding de 3 dado que el kernel es 7x7 ((7-1/2)) para no perder los bordes\n",
    "        self.conv6 = nn.Conv2d(64, 128, kernel_size=7, stride=1, padding=3)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Capa convolicional 7 con 256 filtros, kernel 3x3 con stride de 1 y padding de 1 dado que el kernel es 3x3 para no perder los bordes\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Max Pooling final, este es adaptativo y fuerza la salida a 2x2 dado que la la capa completamente conectada requiere que este tama√±o sea fijo\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((2, 2))\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(256 * 2 * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b38940",
   "metadata": {
    "id": "17b38940"
   },
   "source": [
    "### Definicion de optimizador y funcion de perdida\n",
    "se implementa el optimizador Adam con una tasa de aprendizaje del 0.001 y funcion de perdida CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04925f83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1771471403332,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "04925f83",
    "outputId": "5e0f707b-c117-4c42-bbca-e4e1f7c849cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TumorMRICNN(\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv6): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): AdaptiveAvgPool2d(output_size=(2, 2))\n",
      "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instanciar modelo\n",
    "model_1 = TumorMRICNN(num_classes=4).to(device)\n",
    "\n",
    "# Funci√≥n de p√©rdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizador\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42ea1498",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1771471403338,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "42ea1498",
    "outputId": "baeef5df-5fe5-4464-9ace-9f8ed7bdb2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 180, 180]              40\n",
      "       BatchNorm2d-2          [-1, 4, 180, 180]               8\n",
      "            Conv2d-3          [-1, 8, 180, 180]             296\n",
      "       BatchNorm2d-4          [-1, 8, 180, 180]              16\n",
      "         MaxPool2d-5            [-1, 8, 90, 90]               0\n",
      "            Conv2d-6           [-1, 16, 90, 90]           3,216\n",
      "       BatchNorm2d-7           [-1, 16, 90, 90]              32\n",
      "            Conv2d-8           [-1, 32, 90, 90]          12,832\n",
      "       BatchNorm2d-9           [-1, 32, 90, 90]              64\n",
      "           Conv2d-10           [-1, 64, 90, 90]          51,264\n",
      "      BatchNorm2d-11           [-1, 64, 90, 90]             128\n",
      "        MaxPool2d-12           [-1, 64, 45, 45]               0\n",
      "           Conv2d-13          [-1, 128, 45, 45]         401,536\n",
      "      BatchNorm2d-14          [-1, 128, 45, 45]             256\n",
      "           Conv2d-15          [-1, 256, 45, 45]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 45, 45]             512\n",
      "AdaptiveAvgPool2d-17            [-1, 256, 2, 2]               0\n",
      "           Linear-18                    [-1, 4]           4,100\n",
      "================================================================\n",
      "Total params: 769,468\n",
      "Trainable params: 769,468\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 33.13\n",
      "Params size (MB): 2.94\n",
      "Estimated Total Size (MB): 36.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_1, input_size=(1, 180, 180))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6bfd0b",
   "metadata": {
    "id": "3b6bfd0b"
   },
   "source": [
    "### Entrenamiento y evaluaci√≥n del modelo\n",
    "\n",
    "Se aplican las funciones de entrenamiento y evaluaci√≥n en un bucle durante 150 √©pocas con una parada temprana de 20, observando el progreso del modelo en cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f90cc599",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 479945,
     "status": "ok",
     "timestamp": 1771471883285,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "f90cc599",
    "outputId": "35c3067b-1ea7-43ea-a62c-c5ff1c4aa7a9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 0.8130 | Train Acc: 0.6630 | Val Loss: 0.9010 | Val Acc: 0.6512\n",
      "Mejor modelo guardado en la √©poca 1 con p√©rdida de validaci√≥n 0.9010\n",
      "Epoch [2/20] | Train Loss: 0.6450 | Train Acc: 0.7412 | Val Loss: 0.5630 | Val Acc: 0.7929\n",
      "Mejor modelo guardado en la √©poca 2 con p√©rdida de validaci√≥n 0.5630\n",
      "Epoch [3/20] | Train Loss: 0.5757 | Train Acc: 0.7668 | Val Loss: 0.5776 | Val Acc: 0.7751\n",
      "Epoch [4/20] | Train Loss: 0.5215 | Train Acc: 0.7913 | Val Loss: 0.6423 | Val Acc: 0.7203\n",
      "Epoch [5/20] | Train Loss: 0.4631 | Train Acc: 0.8213 | Val Loss: 0.6001 | Val Acc: 0.7872\n",
      "Epoch [6/20] | Train Loss: 0.4138 | Train Acc: 0.8361 | Val Loss: 0.7480 | Val Acc: 0.7103\n",
      "Epoch [7/20] | Train Loss: 0.3952 | Train Acc: 0.8488 | Val Loss: 0.4735 | Val Acc: 0.8214\n",
      "Mejor modelo guardado en la √©poca 7 con p√©rdida de validaci√≥n 0.4735\n",
      "Epoch [8/20] | Train Loss: 0.3526 | Train Acc: 0.8630 | Val Loss: 0.4951 | Val Acc: 0.8100\n",
      "Epoch [9/20] | Train Loss: 0.3094 | Train Acc: 0.8827 | Val Loss: 0.2717 | Val Acc: 0.9053\n",
      "Mejor modelo guardado en la √©poca 9 con p√©rdida de validaci√≥n 0.2717\n",
      "Epoch [10/20] | Train Loss: 0.3046 | Train Acc: 0.8861 | Val Loss: 0.3627 | Val Acc: 0.8733\n",
      "Epoch [11/20] | Train Loss: 0.2739 | Train Acc: 0.8961 | Val Loss: 0.4620 | Val Acc: 0.8335\n",
      "Epoch [12/20] | Train Loss: 0.2616 | Train Acc: 0.9030 | Val Loss: 0.3133 | Val Acc: 0.8897\n",
      "Epoch [13/20] | Train Loss: 0.2403 | Train Acc: 0.9130 | Val Loss: 0.3052 | Val Acc: 0.8911\n",
      "Epoch [14/20] | Train Loss: 0.2261 | Train Acc: 0.9161 | Val Loss: 0.3048 | Val Acc: 0.8989\n",
      "Parada temprana en la √©poca 14\n",
      "üèÉ View run arq_1_TumorMRICNN at: http://3.89.116.159:8050/#/experiments/1/runs/bfb74e1bac3c49ba91f42463dde1d6af\n",
      "üß™ View experiment at: http://3.89.116.159:8050/#/experiments/1\n",
      "Run registrado en MLflow\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Entrenamiento con MLflow\n",
    "# =========================\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model_wts = copy.deepcopy(model_1.state_dict())\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# (Opcional) nombres de clases\n",
    "class_names = None\n",
    "try:\n",
    "    class_names = val_dataset.classes\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Conteo de par√°metros entrenables\n",
    "trainable_params = sum(p.numel() for p in model_1.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model_1.parameters())\n",
    "\n",
    "with mlflow.start_run(run_name=\"arq_1_TumorMRICNN\"):\n",
    "    # Tags √∫tiles para comparar modelos en MLflow\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"MRI Tumor Classification\",\n",
    "        \"model_arch\": \"TumorMRICNN\",\n",
    "        \"framework\": \"pytorch\",\n",
    "    })\n",
    "\n",
    "    # Par√°metros (ajusta/a√±ade seg√∫n tu caso)\n",
    "    mlflow.log_params({\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"patience\": patience,\n",
    "        \"lr\": optimizer.param_groups[0].get(\"lr\", None),\n",
    "        \"batch_size\": getattr(train_data_load, \"batch_size\", None),\n",
    "        \"img_size\": locals().get(\"img_size\", None),\n",
    "        \"val_split\": locals().get(\"val_split\", None),\n",
    "        \"seed\": locals().get(\"seed\", None),\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"total_params\": total_params,\n",
    "    })\n",
    "\n",
    "    # Guardar arquitectura como artefacto\n",
    "    arch_path = ARTIFACT_DIR / \"arq_1_TumorMRICNN_model_arch.txt\"\n",
    "    arch_path.write_text(str(model_1), encoding=\"utf-8\")\n",
    "    mlflow.log_artifact(str(arch_path))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model_1, train_data_load, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model_1, val_data_load, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Log de m√©tricas por √©poca (clave: step=epoch)\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"train_acc\": float(train_acc),\n",
    "            \"val_acc\": float(val_acc),\n",
    "        }, step=epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "              f'| Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} '\n",
    "              f'| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Guardar mejor modelo\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model_1.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model_1.state_dict(), 'best_model_arq_1.pth')\n",
    "            mlflow.log_metric(\"best_val_loss\", float(best_val_loss), step=epoch)\n",
    "            print(f\"Mejor modelo guardado en la √©poca {epoch+1} con p√©rdida de validaci√≥n {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Parada temprana en la √©poca {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Cargar el mejor modelo al final\n",
    "    model_1.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Curvas como artefacto\n",
    "    prefix = \"arq_1_TumorMRICNN\"\n",
    "    log_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, prefix)\n",
    "\n",
    "    # Log del checkpoint final (mejor)\n",
    "    if os.path.exists('best_model_arq_1.pth'):\n",
    "        mlflow.log_artifact('best_model_arq_1.pth')\n",
    "\n",
    "    # Evaluaci√≥n final + artefactos (reporte + matriz confusi√≥n)\n",
    "    _ = evaluate_and_log(model_1, val_data_load, device, prefix=prefix, class_names=class_names)\n",
    "\n",
    "print(\"Run registrado en MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d814a35b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1771471883335,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "d814a35b",
    "outputId": "f901039c-3f3f-4b2e-d44e-7d6ec3119933"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TumorMRICNN(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv6): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar mejor modelo para sacar metricas\n",
    "model_1 = TumorMRICNN(num_classes=4).to(device)\n",
    "model_1.load_state_dict(torch.load('best_model_arq_1.pth'))\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f9096",
   "metadata": {
    "id": "736f9096"
   },
   "source": [
    "### Reporte de clasificaci√≥n arquitectura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0555fad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5588,
     "status": "ok",
     "timestamp": 1771471888924,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "e0555fad",
    "outputId": "32842614-102a-4c43-a3e7-06557b70e949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.88      0.91      0.90       324\n",
      "     healthy       0.95      0.96      0.95       400\n",
      "  meningioma       0.83      0.80      0.81       329\n",
      "   pituitary       0.95      0.93      0.94       352\n",
      "\n",
      "    accuracy                           0.91      1405\n",
      "   macro avg       0.90      0.90      0.90      1405\n",
      "weighted avg       0.90      0.91      0.91      1405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener todas las predicciones y etiquetas verdaderas\n",
    "y_true_1 = []\n",
    "y_pred_1 = []\n",
    "\n",
    "model_1.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_data_load:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_1(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true_1.extend(labels.cpu().numpy())\n",
    "        y_pred_1.extend(preds.cpu().numpy())\n",
    "\n",
    "# Reporte detallado\n",
    "print(classification_report(y_true_1, y_pred_1, target_names=val_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c5288",
   "metadata": {
    "id": "459c5288"
   },
   "source": [
    "### Arquitectura # 2 Red Neuronal Convolicional (CNN)\n",
    "\n",
    "Cada bloque contiene:\n",
    "\n",
    "* Dos capas Conv2D con kernel 3x3 y padding=1.\n",
    "* Batch Normalization despu√©s de cada convoluci√≥n.\n",
    "* Activaci√≥n ReLU.\n",
    "* MaxPooling2D (2x2) para reducir el tama√±o espacial.\n",
    "* Dropout para evitar sobreajuste (25%).\n",
    "\n",
    "La cantidad de filtros en los bloques es:\n",
    "\n",
    "* 1¬∞ bloque: 64 filtros\n",
    "* 2¬∞ bloque: 32 filtros\n",
    "* 3¬∞ bloque: 16 filtros\n",
    "* 4¬∞ bloque: 8 filtros\n",
    "\n",
    "Capas Finales\n",
    "\n",
    "* Flatten del tensor\n",
    "* Capa densa de 968 unidades a 1024 unidades, con Dropout (50%).\n",
    "* Capa de salida de 1024 a 4 unidades (una por clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a2185d3",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1771471888925,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "4a2185d3"
   },
   "outputs": [],
   "source": [
    "class MultiClassifier1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassifier1, self).__init__()\n",
    "\n",
    "        #-------------------- Primer bloque convolucional --------------------------\n",
    "        # Capa convolicional 1 con entrada (1 canal) , con 64 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64) # Normalizaci√≥n por lotes\n",
    "\n",
    "        # Capa convolicional 2 con 64 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64) # Normalizaci√≥n por lotes\n",
    "\n",
    "        # Max Pooling para Reducci√≥n de tama√±o espacial\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        # Dropout para evitar sobreajuste\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        #-------------------- Segundo bloque convolucional --------------------------\n",
    "        # Capa convolicional 3 con 32 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Capa convolicional 4 con 32 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Max Pooling para Reducci√≥n de tama√±o espacial\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        # Dropout para evitar sobreajuste\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        #-------------------- Tercer bloque convolucional --------------------------\n",
    "        # Capa convolicional 5 con 16 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv5 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Capa convolicional 6 con 16 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv6 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Max Pooling para Reducci√≥n de tama√±o espacial\n",
    "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
    "        # Dropout para evitar sobreajuste\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "\n",
    "        #-------------------- Cuarto bloque convolucional --------------------------\n",
    "        # Capa convolicional 7 con 8 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv7 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Capa convolicional 8 con 8 filtros, kernel 3x3 y padding para no perder los bordes\n",
    "        self.conv8 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Max Pooling para Reducci√≥n de tama√±o espacial\n",
    "        self.maxpool4 = nn.MaxPool2d(2, 2)\n",
    "        # Dropout para evitar sobreajuste\n",
    "        self.dropout4 = nn.Dropout(0.25)\n",
    "\n",
    "        # Capa de flatten para convertir el tensor en vector\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Capa densa 1 completamente conectada\n",
    "        self.fc1 = nn.Linear(8 * 11 * 11, 1024)  # 8x11x11 debido a la reducci√≥n de tama√±o en las capas previas\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "\n",
    "        # Capa de salida\n",
    "        self.fc2 = nn.Linear(1024, 4)  # 4 clases para la clasificaci√≥n\n",
    "\n",
    "    def forward(self, x):\n",
    "        # se pasan las im√°genes a trav√©s de las capas convolucionales\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        # Aplanamos la salida para las capas totalmente conectadas\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Capa densa 1\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout5(x)\n",
    "\n",
    "        # Capa de salida (para clasificaci√≥n)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91e1be",
   "metadata": {
    "id": "6c91e1be"
   },
   "source": [
    "### Definicion de optimizador y funcion de perdida\n",
    "se implementa el optimizador Adam con una tasa de aprendizaje del 0.001 y funcion de perdida CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5d86a74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1771471888926,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "b5d86a74",
    "outputId": "613d287f-85c4-4b89-c5a6-c397b53bee34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassifier1(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout(p=0.25, inplace=False)\n",
      "  (conv5): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout3): Dropout(p=0.25, inplace=False)\n",
      "  (conv7): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout4): Dropout(p=0.25, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=968, out_features=1024, bias=True)\n",
      "  (dropout5): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instancia del modelo\n",
    "model_2 = MultiClassifier1().to(device)\n",
    "\n",
    "# funcion de perdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizador\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "print(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4432788d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1771471889016,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "4432788d",
    "outputId": "8ec56106-1463-4f42-8d71-92c016bb890c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 180, 180]             640\n",
      "       BatchNorm2d-2         [-1, 64, 180, 180]             128\n",
      "            Conv2d-3         [-1, 64, 180, 180]          36,928\n",
      "       BatchNorm2d-4         [-1, 64, 180, 180]             128\n",
      "         MaxPool2d-5           [-1, 64, 90, 90]               0\n",
      "           Dropout-6           [-1, 64, 90, 90]               0\n",
      "            Conv2d-7           [-1, 32, 90, 90]          18,464\n",
      "       BatchNorm2d-8           [-1, 32, 90, 90]              64\n",
      "            Conv2d-9           [-1, 32, 90, 90]           9,248\n",
      "      BatchNorm2d-10           [-1, 32, 90, 90]              64\n",
      "        MaxPool2d-11           [-1, 32, 45, 45]               0\n",
      "          Dropout-12           [-1, 32, 45, 45]               0\n",
      "           Conv2d-13           [-1, 16, 45, 45]           4,624\n",
      "      BatchNorm2d-14           [-1, 16, 45, 45]              32\n",
      "           Conv2d-15           [-1, 16, 45, 45]           2,320\n",
      "      BatchNorm2d-16           [-1, 16, 45, 45]              32\n",
      "        MaxPool2d-17           [-1, 16, 22, 22]               0\n",
      "          Dropout-18           [-1, 16, 22, 22]               0\n",
      "           Conv2d-19            [-1, 8, 22, 22]           1,160\n",
      "      BatchNorm2d-20            [-1, 8, 22, 22]              16\n",
      "           Conv2d-21            [-1, 8, 22, 22]             584\n",
      "      BatchNorm2d-22            [-1, 8, 22, 22]              16\n",
      "        MaxPool2d-23            [-1, 8, 11, 11]               0\n",
      "          Dropout-24            [-1, 8, 11, 11]               0\n",
      "          Flatten-25                  [-1, 968]               0\n",
      "           Linear-26                 [-1, 1024]         992,256\n",
      "          Dropout-27                 [-1, 1024]               0\n",
      "           Linear-28                    [-1, 4]           4,100\n",
      "================================================================\n",
      "Total params: 1,070,804\n",
      "Trainable params: 1,070,804\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 81.35\n",
      "Params size (MB): 4.08\n",
      "Estimated Total Size (MB): 85.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_2, input_size=(1, 180, 180))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef179c",
   "metadata": {
    "id": "8aef179c"
   },
   "source": [
    "### Entrenamiento y evaluaci√≥n del modelo\n",
    "\n",
    "Se aplican las funciones de entrenamiento y evaluaci√≥n en un bucle durante 150 √©pocas con una parada temprana de 20, observando el progreso del modelo en cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5378e08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646891,
     "status": "ok",
     "timestamp": 1771472535908,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "d5378e08",
    "outputId": "6f6a6ead-e8d5-4196-d7b0-bd9b23520499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 0.8881 | Train Acc: 0.6284 | Val Loss: 0.5709 | Val Acc: 0.7765\n",
      "Mejor modelo guardado en la √©poca 1 con p√©rdida de validaci√≥n 0.5709\n",
      "Epoch [2/20] | Train Loss: 0.6407 | Train Acc: 0.7377 | Val Loss: 0.4651 | Val Acc: 0.8235\n",
      "Mejor modelo guardado en la √©poca 2 con p√©rdida de validaci√≥n 0.4651\n",
      "Epoch [3/20] | Train Loss: 0.5706 | Train Acc: 0.7684 | Val Loss: 0.4862 | Val Acc: 0.7751\n",
      "Epoch [4/20] | Train Loss: 0.4907 | Train Acc: 0.7982 | Val Loss: 0.4856 | Val Acc: 0.8142\n",
      "Epoch [5/20] | Train Loss: 0.4628 | Train Acc: 0.8170 | Val Loss: 0.3676 | Val Acc: 0.8676\n",
      "Mejor modelo guardado en la √©poca 5 con p√©rdida de validaci√≥n 0.3676\n",
      "Epoch [6/20] | Train Loss: 0.4467 | Train Acc: 0.8227 | Val Loss: 0.3520 | Val Acc: 0.8683\n",
      "Mejor modelo guardado en la √©poca 6 con p√©rdida de validaci√≥n 0.3520\n",
      "Epoch [7/20] | Train Loss: 0.4055 | Train Acc: 0.8361 | Val Loss: 0.3446 | Val Acc: 0.8790\n",
      "Mejor modelo guardado en la √©poca 7 con p√©rdida de validaci√≥n 0.3446\n",
      "Epoch [8/20] | Train Loss: 0.3804 | Train Acc: 0.8532 | Val Loss: 0.3625 | Val Acc: 0.8683\n",
      "Epoch [9/20] | Train Loss: 0.3638 | Train Acc: 0.8589 | Val Loss: 0.2970 | Val Acc: 0.8954\n",
      "Mejor modelo guardado en la √©poca 9 con p√©rdida de validaci√≥n 0.2970\n",
      "Epoch [10/20] | Train Loss: 0.3420 | Train Acc: 0.8688 | Val Loss: 0.3386 | Val Acc: 0.8861\n",
      "Epoch [11/20] | Train Loss: 0.3292 | Train Acc: 0.8786 | Val Loss: 0.2605 | Val Acc: 0.8989\n",
      "Mejor modelo guardado en la √©poca 11 con p√©rdida de validaci√≥n 0.2605\n",
      "Epoch [12/20] | Train Loss: 0.2926 | Train Acc: 0.8870 | Val Loss: 0.2390 | Val Acc: 0.9139\n",
      "Mejor modelo guardado en la √©poca 12 con p√©rdida de validaci√≥n 0.2390\n",
      "Epoch [13/20] | Train Loss: 0.2908 | Train Acc: 0.8909 | Val Loss: 0.2462 | Val Acc: 0.9139\n",
      "Epoch [14/20] | Train Loss: 0.2627 | Train Acc: 0.9009 | Val Loss: 0.2151 | Val Acc: 0.9238\n",
      "Mejor modelo guardado en la √©poca 14 con p√©rdida de validaci√≥n 0.2151\n",
      "Epoch [15/20] | Train Loss: 0.2677 | Train Acc: 0.9036 | Val Loss: 0.2014 | Val Acc: 0.9338\n",
      "Mejor modelo guardado en la √©poca 15 con p√©rdida de validaci√≥n 0.2014\n",
      "Epoch [16/20] | Train Loss: 0.2480 | Train Acc: 0.9064 | Val Loss: 0.1768 | Val Acc: 0.9452\n",
      "Mejor modelo guardado en la √©poca 16 con p√©rdida de validaci√≥n 0.1768\n",
      "Epoch [17/20] | Train Loss: 0.2191 | Train Acc: 0.9225 | Val Loss: 0.1944 | Val Acc: 0.9324\n",
      "Epoch [18/20] | Train Loss: 0.2230 | Train Acc: 0.9177 | Val Loss: 0.1479 | Val Acc: 0.9530\n",
      "Mejor modelo guardado en la √©poca 18 con p√©rdida de validaci√≥n 0.1479\n",
      "Epoch [19/20] | Train Loss: 0.2244 | Train Acc: 0.9175 | Val Loss: 0.1459 | Val Acc: 0.9516\n",
      "Mejor modelo guardado en la √©poca 19 con p√©rdida de validaci√≥n 0.1459\n",
      "Epoch [20/20] | Train Loss: 0.1955 | Train Acc: 0.9214 | Val Loss: 0.1506 | Val Acc: 0.9516\n",
      "üèÉ View run arq_2_MultiClassifier1 at: http://3.89.116.159:8050/#/experiments/1/runs/20cbecd06454423f8b9adc066a92eb57\n",
      "üß™ View experiment at: http://3.89.116.159:8050/#/experiments/1\n",
      "Run registrado en MLflow\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Entrenamiento con MLflow\n",
    "# =========================\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model_wts = copy.deepcopy(model_2.state_dict())\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# (Opcional) nombres de clases\n",
    "class_names = None\n",
    "try:\n",
    "    class_names = val_dataset.classes\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Conteo de par√°metros entrenables\n",
    "trainable_params = sum(p.numel() for p in model_2.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model_2.parameters())\n",
    "\n",
    "with mlflow.start_run(run_name=\"arq_2_MultiClassifier1\"):\n",
    "    # Tags √∫tiles para comparar modelos en MLflow\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"MRI Tumor Classification\",\n",
    "        \"model_arch\": \"MultiClassifier1\",\n",
    "        \"framework\": \"pytorch\",\n",
    "    })\n",
    "\n",
    "    # Par√°metros (ajusta/a√±ade seg√∫n tu caso)\n",
    "    mlflow.log_params({\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"patience\": patience,\n",
    "        \"lr\": optimizer.param_groups[0].get(\"lr\", None),\n",
    "        \"batch_size\": getattr(train_data_load, \"batch_size\", None),\n",
    "        \"img_size\": locals().get(\"img_size\", None),\n",
    "        \"val_split\": locals().get(\"val_split\", None),\n",
    "        \"seed\": locals().get(\"seed\", None),\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"total_params\": total_params,\n",
    "    })\n",
    "\n",
    "    # Guardar arquitectura como artefacto\n",
    "    arch_path = ARTIFACT_DIR / \"arq_2_MultiClassifier1_model_arch.txt\"\n",
    "    arch_path.write_text(str(model_2), encoding=\"utf-8\")\n",
    "    mlflow.log_artifact(str(arch_path))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model_2, train_data_load, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model_2, val_data_load, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Log de m√©tricas por √©poca (clave: step=epoch)\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"train_acc\": float(train_acc),\n",
    "            \"val_acc\": float(val_acc),\n",
    "        }, step=epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "              f'| Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} '\n",
    "              f'| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Guardar mejor modelo\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model_2.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model_2.state_dict(), 'best_model_arq_2.pth')\n",
    "            mlflow.log_metric(\"best_val_loss\", float(best_val_loss), step=epoch)\n",
    "            print(f\"Mejor modelo guardado en la √©poca {epoch+1} con p√©rdida de validaci√≥n {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Parada temprana en la √©poca {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Cargar el mejor modelo al final\n",
    "    model_2.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Curvas como artefacto\n",
    "    prefix = \"arq_2_MultiClassifier1\"\n",
    "    log_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, prefix)\n",
    "\n",
    "    # Log del checkpoint final (mejor)\n",
    "    if os.path.exists('best_model_arq_2.pth'):\n",
    "        mlflow.log_artifact('best_model_arq_2.pth')\n",
    "\n",
    "    # Evaluaci√≥n final + artefactos (reporte + matriz confusi√≥n)\n",
    "    _ = evaluate_and_log(model_2, val_data_load, device, prefix=prefix, class_names=class_names)\n",
    "\n",
    "print(\"Run registrado en MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38155e64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1771472535943,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "38155e64",
    "outputId": "b77258f5-7b33-4040-9cba-0557c6d12505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiClassifier1(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.25, inplace=False)\n",
       "  (conv5): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout(p=0.25, inplace=False)\n",
       "  (conv7): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout4): Dropout(p=0.25, inplace=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=968, out_features=1024, bias=True)\n",
       "  (dropout5): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar mejor modelo para sacar metricas\n",
    "model_2 = MultiClassifier1().to(device)\n",
    "model_2.load_state_dict(torch.load('best_model_arq_2.pth'))\n",
    "model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24f85b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1771472535968,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "24f85b7b",
    "outputId": "1d06e77f-2c30-4e16-cec1-6dbf6c1476e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 180, 180]             640\n",
      "       BatchNorm2d-2         [-1, 64, 180, 180]             128\n",
      "            Conv2d-3         [-1, 64, 180, 180]          36,928\n",
      "       BatchNorm2d-4         [-1, 64, 180, 180]             128\n",
      "         MaxPool2d-5           [-1, 64, 90, 90]               0\n",
      "           Dropout-6           [-1, 64, 90, 90]               0\n",
      "            Conv2d-7           [-1, 32, 90, 90]          18,464\n",
      "       BatchNorm2d-8           [-1, 32, 90, 90]              64\n",
      "            Conv2d-9           [-1, 32, 90, 90]           9,248\n",
      "      BatchNorm2d-10           [-1, 32, 90, 90]              64\n",
      "        MaxPool2d-11           [-1, 32, 45, 45]               0\n",
      "          Dropout-12           [-1, 32, 45, 45]               0\n",
      "           Conv2d-13           [-1, 16, 45, 45]           4,624\n",
      "      BatchNorm2d-14           [-1, 16, 45, 45]              32\n",
      "           Conv2d-15           [-1, 16, 45, 45]           2,320\n",
      "      BatchNorm2d-16           [-1, 16, 45, 45]              32\n",
      "        MaxPool2d-17           [-1, 16, 22, 22]               0\n",
      "          Dropout-18           [-1, 16, 22, 22]               0\n",
      "           Conv2d-19            [-1, 8, 22, 22]           1,160\n",
      "      BatchNorm2d-20            [-1, 8, 22, 22]              16\n",
      "           Conv2d-21            [-1, 8, 22, 22]             584\n",
      "      BatchNorm2d-22            [-1, 8, 22, 22]              16\n",
      "        MaxPool2d-23            [-1, 8, 11, 11]               0\n",
      "          Dropout-24            [-1, 8, 11, 11]               0\n",
      "          Flatten-25                  [-1, 968]               0\n",
      "           Linear-26                 [-1, 1024]         992,256\n",
      "          Dropout-27                 [-1, 1024]               0\n",
      "           Linear-28                    [-1, 4]           4,100\n",
      "================================================================\n",
      "Total params: 1,070,804\n",
      "Trainable params: 1,070,804\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 81.35\n",
      "Params size (MB): 4.08\n",
      "Estimated Total Size (MB): 85.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_2, input_size=(1, 180, 180))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a58d2d",
   "metadata": {
    "id": "c4a58d2d"
   },
   "source": [
    "### Arquitectura # 3 Red Neuronal Convolicional (CNN)  - EfficientNetB0\n",
    "\n",
    "Esta CNN cuenta con tres \"Grandes\" bloques:\n",
    "\n",
    "Bloque 1: Busca extraer caracter√≠sticas simples (Bordes, contornos y patrones simples):\n",
    "\n",
    "\n",
    "* Capa 1 Conv2d: 32 filtros, kernel 3x3 y padding=1.\n",
    "* Batch Normalization despu√©s de cada convoluci√≥n.\n",
    "* Maxpool: 2x2, reduce resoluci√≥n a la mitad\n",
    "\n",
    "\n",
    "Bloque 2: Este bloque en relidad cuenta con 16 bloques de MBConv (Mobile Inverted Bottleneck Convolution), busca extraer caracter√≠sticas como texturas y formas m√°s complejas:\n",
    "\n",
    "| Etapa | Tipo de bloque | # Bloques | Filtros (in ‚Üí out) | Kernel |\n",
    "|-------|----------------|-----------|---------------------|--------|\n",
    "| MBConv1 | 1 bloque     | 1         | 32 ‚Üí 16             | 3√ó3    |\n",
    "| MBConv6 | 2 bloques    | 2         | 16 ‚Üí 24             | 3√ó3    |\n",
    "| MBConv6 | 2 bloques    | 2         | 24 ‚Üí 40             | 5√ó5    |\n",
    "| MBConv6 | 3 bloques    | 3         | 40 ‚Üí 80             | 3√ó3    |\n",
    "| MBConv6 | 3 bloques    | 3         | 80 ‚Üí 112            | 5√ó5    |\n",
    "| MBConv6 | 4 bloques    | 4         | 112 ‚Üí 192           | 5√ó5    |\n",
    "| MBConv6 | 1 bloque     | 1         | 192 ‚Üí 320           | 3√ó3    |\n",
    "\n",
    "\n",
    "Bloque 3: Bloque de clasificaci√≥n (4 clases):\n",
    "\n",
    "* Capa 1 Conv2d: 1280 filtros, kernel 1x1 y padding=1.\n",
    "* AdaptiveAvgPool2d(1√ó1)\n",
    "* Dropout(p=0.2)\n",
    "* Capa densa: Predicci√≥n de clases (linear)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf87ba8",
   "metadata": {
    "id": "4bf87ba8"
   },
   "source": [
    "### Preprocesado:\n",
    "\n",
    "Dada la literatura, esta red es recomendable con un tama√±o de im√°gen de 224x224, con tres canales y una normalizaci√≥n propia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "354b3229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1771472535980,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "354b3229",
    "outputId": "de5a73b2-1b79-45d2-8cb3-4f1ef866ab99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ec9ac0451f0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tama√±o de las im√°genes\n",
    "img_size = 224\n",
    "\n",
    "# Tama√±o de batch\n",
    "batch_size = 16\n",
    "\n",
    "# Porcentaje de datos para validaci√≥n\n",
    "val_split = 0.2\n",
    "\n",
    "# Semilla\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e319364",
   "metadata": {
    "id": "6e319364"
   },
   "source": [
    "###  Pipeline de preprocesamiento\n",
    "\n",
    "A continuacion se se crea el pipeline de preprocesamiento de images, el cual realiza los siguientes pasos:\n",
    "* redimensiona la imagen a 224x224\n",
    "* se aplica normalizacion propia para esta red\n",
    "------\n",
    "Para el conjunto de datos de entrenamiento, se decide aplicar, adem√°s de los pasos previos, t√©cnicas de aumento de datos (data augmentation) para enriquecer la variedad de ejemplos y mejorar la generalizaci√≥n del modelo.\n",
    "* se  refleja la imagen de izquierda a derecha.\n",
    "* se rota la imagen de manera aleatoria entre -15 y 15 grados.\n",
    "* se ajusta aleatoriamente el brillo y el contraste de la imagen dentro de un rango de 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fb4fcf1",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1771472536000,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "5fb4fcf1"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalizaci√≥n est√°ndar ImageNet\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958ca49",
   "metadata": {
    "id": "8958ca49"
   },
   "source": [
    "### Division del dataset\n",
    "\n",
    "El dataset se divide en datos de train y val. Adicional, se aplica el pipeline de preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b95a42e",
   "metadata": {
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1771472536087,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "8b95a42e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "NUM_WORKERS = int(os.getenv('NUM_WORKERS','2'))\n",
    "# Cargar el dataset con ImageFolder dado que la estructura provienen de directorios\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path)\n",
    "\n",
    "# Obtener las etiquetas de las im√°genes\n",
    "labels = [item[1] for item in dataset.samples]\n",
    "\n",
    "# Dividimos el dataset de manera estratificada\n",
    "Stratified = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=seed)\n",
    "\n",
    "for train_index, val_index in Stratified.split(np.zeros(len(labels)), labels):\n",
    "    pass  # Solo necesitamos una divisi√≥n\n",
    "\n",
    "# Con transform aplicar el pipeline de preprocesado espeficado en la celda anterior para cada dataset\n",
    "train_dataset = ImageFolder(root=dataset_path, transform=train_transform)\n",
    "val_dataset = ImageFolder(root=dataset_path, transform=val_transform)\n",
    "\n",
    "# Seleccionamos los indices adecuado de cada dataset transformado\n",
    "train_db = torch.utils.data.Subset(train_dataset, train_index)\n",
    "val_db = torch.utils.data.Subset(val_dataset, val_index)\n",
    "\n",
    "# Cargamos los datos por baches\n",
    "train_data_load = DataLoader(train_db, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_data_load = DataLoader(val_db, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f826c",
   "metadata": {
    "id": "cf1f826c"
   },
   "source": [
    "###  Intanciar el modelo y configurar el proceso de transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d440d61d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1771472536428,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "d440d61d",
    "outputId": "623193d3-f6b2-4c04-9243-1dbff0ba7e47"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 176MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_3 = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Descongelar capas para realizar el proceso de Fine-tuning con los datos propios\n",
    "for param in model_3.features.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Reemplazar la √∫ltima capa para clasificaci√≥n en 4 clases\n",
    "num_features = model_3.classifier[1].in_features\n",
    "model_3.classifier[1] = nn.Linear(num_features, 4)  # 4 clases: glioma, meningioma, pituitary, healthy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b6d15",
   "metadata": {
    "id": "743b6d15"
   },
   "source": [
    "### Definicion de optimizador y funcion de perdida\n",
    "se implementa el optimizador Adam con una tasa de aprendizaje del 0.001 y funcion de perdida CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c05019d",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1771472536448,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "6c05019d"
   },
   "outputs": [],
   "source": [
    "model_3 = model_3.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_3.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0859eb96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1771472536795,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "0859eb96",
    "outputId": "180fa145-dfb8-4f0e-caf6-ef7a5af38b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              SiLU-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "              SiLU-6         [-1, 32, 112, 112]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]             264\n",
      "              SiLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
      "SqueezeExcitation-12         [-1, 32, 112, 112]               0\n",
      "           Conv2d-13         [-1, 16, 112, 112]             512\n",
      "      BatchNorm2d-14         [-1, 16, 112, 112]              32\n",
      "           MBConv-15         [-1, 16, 112, 112]               0\n",
      "           Conv2d-16         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-17         [-1, 96, 112, 112]             192\n",
      "             SiLU-18         [-1, 96, 112, 112]               0\n",
      "           Conv2d-19           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-20           [-1, 96, 56, 56]             192\n",
      "             SiLU-21           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
      "           Conv2d-23              [-1, 4, 1, 1]             388\n",
      "             SiLU-24              [-1, 4, 1, 1]               0\n",
      "           Conv2d-25             [-1, 96, 1, 1]             480\n",
      "          Sigmoid-26             [-1, 96, 1, 1]               0\n",
      "SqueezeExcitation-27           [-1, 96, 56, 56]               0\n",
      "           Conv2d-28           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-29           [-1, 24, 56, 56]              48\n",
      "           MBConv-30           [-1, 24, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-32          [-1, 144, 56, 56]             288\n",
      "             SiLU-33          [-1, 144, 56, 56]               0\n",
      "           Conv2d-34          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-35          [-1, 144, 56, 56]             288\n",
      "             SiLU-36          [-1, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-37            [-1, 144, 1, 1]               0\n",
      "           Conv2d-38              [-1, 6, 1, 1]             870\n",
      "             SiLU-39              [-1, 6, 1, 1]               0\n",
      "           Conv2d-40            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-41            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-42          [-1, 144, 56, 56]               0\n",
      "           Conv2d-43           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-44           [-1, 24, 56, 56]              48\n",
      "  StochasticDepth-45           [-1, 24, 56, 56]               0\n",
      "           MBConv-46           [-1, 24, 56, 56]               0\n",
      "           Conv2d-47          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-48          [-1, 144, 56, 56]             288\n",
      "             SiLU-49          [-1, 144, 56, 56]               0\n",
      "           Conv2d-50          [-1, 144, 28, 28]           3,600\n",
      "      BatchNorm2d-51          [-1, 144, 28, 28]             288\n",
      "             SiLU-52          [-1, 144, 28, 28]               0\n",
      "AdaptiveAvgPool2d-53            [-1, 144, 1, 1]               0\n",
      "           Conv2d-54              [-1, 6, 1, 1]             870\n",
      "             SiLU-55              [-1, 6, 1, 1]               0\n",
      "           Conv2d-56            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-57            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-58          [-1, 144, 28, 28]               0\n",
      "           Conv2d-59           [-1, 40, 28, 28]           5,760\n",
      "      BatchNorm2d-60           [-1, 40, 28, 28]              80\n",
      "           MBConv-61           [-1, 40, 28, 28]               0\n",
      "           Conv2d-62          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-63          [-1, 240, 28, 28]             480\n",
      "             SiLU-64          [-1, 240, 28, 28]               0\n",
      "           Conv2d-65          [-1, 240, 28, 28]           6,000\n",
      "      BatchNorm2d-66          [-1, 240, 28, 28]             480\n",
      "             SiLU-67          [-1, 240, 28, 28]               0\n",
      "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
      "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-70             [-1, 10, 1, 1]               0\n",
      "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-73          [-1, 240, 28, 28]               0\n",
      "           Conv2d-74           [-1, 40, 28, 28]           9,600\n",
      "      BatchNorm2d-75           [-1, 40, 28, 28]              80\n",
      "  StochasticDepth-76           [-1, 40, 28, 28]               0\n",
      "           MBConv-77           [-1, 40, 28, 28]               0\n",
      "           Conv2d-78          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-79          [-1, 240, 28, 28]             480\n",
      "             SiLU-80          [-1, 240, 28, 28]               0\n",
      "           Conv2d-81          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-82          [-1, 240, 14, 14]             480\n",
      "             SiLU-83          [-1, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-84            [-1, 240, 1, 1]               0\n",
      "           Conv2d-85             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-86             [-1, 10, 1, 1]               0\n",
      "           Conv2d-87            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-88            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-89          [-1, 240, 14, 14]               0\n",
      "           Conv2d-90           [-1, 80, 14, 14]          19,200\n",
      "      BatchNorm2d-91           [-1, 80, 14, 14]             160\n",
      "           MBConv-92           [-1, 80, 14, 14]               0\n",
      "           Conv2d-93          [-1, 480, 14, 14]          38,400\n",
      "      BatchNorm2d-94          [-1, 480, 14, 14]             960\n",
      "             SiLU-95          [-1, 480, 14, 14]               0\n",
      "           Conv2d-96          [-1, 480, 14, 14]           4,320\n",
      "      BatchNorm2d-97          [-1, 480, 14, 14]             960\n",
      "             SiLU-98          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
      "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-101             [-1, 20, 1, 1]               0\n",
      "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-103            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-104          [-1, 480, 14, 14]               0\n",
      "          Conv2d-105           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-106           [-1, 80, 14, 14]             160\n",
      " StochasticDepth-107           [-1, 80, 14, 14]               0\n",
      "          MBConv-108           [-1, 80, 14, 14]               0\n",
      "          Conv2d-109          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-110          [-1, 480, 14, 14]             960\n",
      "            SiLU-111          [-1, 480, 14, 14]               0\n",
      "          Conv2d-112          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-113          [-1, 480, 14, 14]             960\n",
      "            SiLU-114          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
      "          Conv2d-116             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-117             [-1, 20, 1, 1]               0\n",
      "          Conv2d-118            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-119            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-120          [-1, 480, 14, 14]               0\n",
      "          Conv2d-121           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-122           [-1, 80, 14, 14]             160\n",
      " StochasticDepth-123           [-1, 80, 14, 14]               0\n",
      "          MBConv-124           [-1, 80, 14, 14]               0\n",
      "          Conv2d-125          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-126          [-1, 480, 14, 14]             960\n",
      "            SiLU-127          [-1, 480, 14, 14]               0\n",
      "          Conv2d-128          [-1, 480, 14, 14]          12,000\n",
      "     BatchNorm2d-129          [-1, 480, 14, 14]             960\n",
      "            SiLU-130          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-131            [-1, 480, 1, 1]               0\n",
      "          Conv2d-132             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-133             [-1, 20, 1, 1]               0\n",
      "          Conv2d-134            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-135            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-136          [-1, 480, 14, 14]               0\n",
      "          Conv2d-137          [-1, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-138          [-1, 112, 14, 14]             224\n",
      "          MBConv-139          [-1, 112, 14, 14]               0\n",
      "          Conv2d-140          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-141          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-142          [-1, 672, 14, 14]               0\n",
      "          Conv2d-143          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-144          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-145          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-146            [-1, 672, 1, 1]               0\n",
      "          Conv2d-147             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-148             [-1, 28, 1, 1]               0\n",
      "          Conv2d-149            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-150            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-151          [-1, 672, 14, 14]               0\n",
      "          Conv2d-152          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
      " StochasticDepth-154          [-1, 112, 14, 14]               0\n",
      "          MBConv-155          [-1, 112, 14, 14]               0\n",
      "          Conv2d-156          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-157          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-158          [-1, 672, 14, 14]               0\n",
      "          Conv2d-159          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-160          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-161          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
      "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-164             [-1, 28, 1, 1]               0\n",
      "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-167          [-1, 672, 14, 14]               0\n",
      "          Conv2d-168          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
      " StochasticDepth-170          [-1, 112, 14, 14]               0\n",
      "          MBConv-171          [-1, 112, 14, 14]               0\n",
      "          Conv2d-172          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-173          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-174          [-1, 672, 14, 14]               0\n",
      "          Conv2d-175            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-176            [-1, 672, 7, 7]           1,344\n",
      "            SiLU-177            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
      "          Conv2d-179             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-180             [-1, 28, 1, 1]               0\n",
      "          Conv2d-181            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-182            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-183            [-1, 672, 7, 7]               0\n",
      "          Conv2d-184            [-1, 192, 7, 7]         129,024\n",
      "     BatchNorm2d-185            [-1, 192, 7, 7]             384\n",
      "          MBConv-186            [-1, 192, 7, 7]               0\n",
      "          Conv2d-187           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-188           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-189           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-190           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-191           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-192           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-193           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-194             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-195             [-1, 48, 1, 1]               0\n",
      "          Conv2d-196           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-197           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-198           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-199            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-200            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-201            [-1, 192, 7, 7]               0\n",
      "          MBConv-202            [-1, 192, 7, 7]               0\n",
      "          Conv2d-203           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-204           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-205           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-206           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-207           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-208           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-209           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-210             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-211             [-1, 48, 1, 1]               0\n",
      "          Conv2d-212           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-213           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-214           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-215            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-216            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-217            [-1, 192, 7, 7]               0\n",
      "          MBConv-218            [-1, 192, 7, 7]               0\n",
      "          Conv2d-219           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-220           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-221           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-222           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-224           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-225           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-226             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-227             [-1, 48, 1, 1]               0\n",
      "          Conv2d-228           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-229           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-230           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-231            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-232            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-233            [-1, 192, 7, 7]               0\n",
      "          MBConv-234            [-1, 192, 7, 7]               0\n",
      "          Conv2d-235           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-236           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-237           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-238           [-1, 1152, 7, 7]          10,368\n",
      "     BatchNorm2d-239           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-240           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-241           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-242             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-243             [-1, 48, 1, 1]               0\n",
      "          Conv2d-244           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-245           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-246           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-247            [-1, 320, 7, 7]         368,640\n",
      "     BatchNorm2d-248            [-1, 320, 7, 7]             640\n",
      "          MBConv-249            [-1, 320, 7, 7]               0\n",
      "          Conv2d-250           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-251           [-1, 1280, 7, 7]           2,560\n",
      "            SiLU-252           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-253           [-1, 1280, 1, 1]               0\n",
      "         Dropout-254                 [-1, 1280]               0\n",
      "          Linear-255                    [-1, 4]           5,124\n",
      "================================================================\n",
      "Total params: 4,012,672\n",
      "Trainable params: 4,012,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 173.64\n",
      "Params size (MB): 15.31\n",
      "Estimated Total Size (MB): 189.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_3, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ce8c4c",
   "metadata": {
    "id": "82ce8c4c"
   },
   "source": [
    "### Entrenamiento y evaluaci√≥n del modelo\n",
    "\n",
    "Se aplican las funciones de entrenamiento y evaluaci√≥n en un bucle durante 150 √©pocas con una parada temprana de 20, observando el progreso del modelo en cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "05934375",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825560,
     "status": "ok",
     "timestamp": 1771473362360,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "05934375",
    "outputId": "983d2f44-b4da-4c0f-af3d-1814e34c82c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 0.3472 | Train Acc: 0.8749 | Val Loss: 0.1970 | Val Acc: 0.9295\n",
      "Mejor modelo guardado en la √©poca 1 con p√©rdida de validaci√≥n 0.1970\n",
      "Epoch [2/20] | Train Loss: 0.1995 | Train Acc: 0.9349 | Val Loss: 0.1863 | Val Acc: 0.9367\n",
      "Mejor modelo guardado en la √©poca 2 con p√©rdida de validaci√≥n 0.1863\n",
      "Epoch [3/20] | Train Loss: 0.1335 | Train Acc: 0.9583 | Val Loss: 0.0699 | Val Acc: 0.9751\n",
      "Mejor modelo guardado en la √©poca 3 con p√©rdida de validaci√≥n 0.0699\n",
      "Epoch [4/20] | Train Loss: 0.1145 | Train Acc: 0.9639 | Val Loss: 0.0546 | Val Acc: 0.9865\n",
      "Mejor modelo guardado en la √©poca 4 con p√©rdida de validaci√≥n 0.0546\n",
      "Epoch [5/20] | Train Loss: 0.0957 | Train Acc: 0.9699 | Val Loss: 0.0626 | Val Acc: 0.9779\n",
      "Epoch [6/20] | Train Loss: 0.0767 | Train Acc: 0.9760 | Val Loss: 0.0670 | Val Acc: 0.9758\n",
      "Epoch [7/20] | Train Loss: 0.0628 | Train Acc: 0.9788 | Val Loss: 0.0438 | Val Acc: 0.9836\n",
      "Mejor modelo guardado en la √©poca 7 con p√©rdida de validaci√≥n 0.0438\n",
      "Epoch [8/20] | Train Loss: 0.0899 | Train Acc: 0.9705 | Val Loss: 0.0743 | Val Acc: 0.9758\n",
      "Epoch [9/20] | Train Loss: 0.0633 | Train Acc: 0.9797 | Val Loss: 0.0890 | Val Acc: 0.9708\n",
      "Epoch [10/20] | Train Loss: 0.0656 | Train Acc: 0.9827 | Val Loss: 0.0465 | Val Acc: 0.9851\n",
      "Epoch [11/20] | Train Loss: 0.0951 | Train Acc: 0.9701 | Val Loss: 0.0551 | Val Acc: 0.9829\n",
      "Epoch [12/20] | Train Loss: 0.0599 | Train Acc: 0.9794 | Val Loss: 0.0252 | Val Acc: 0.9936\n",
      "Mejor modelo guardado en la √©poca 12 con p√©rdida de validaci√≥n 0.0252\n",
      "Epoch [13/20] | Train Loss: 0.0525 | Train Acc: 0.9815 | Val Loss: 0.0651 | Val Acc: 0.9779\n",
      "Epoch [14/20] | Train Loss: 0.0570 | Train Acc: 0.9815 | Val Loss: 0.0416 | Val Acc: 0.9900\n",
      "Epoch [15/20] | Train Loss: 0.0566 | Train Acc: 0.9813 | Val Loss: 0.0470 | Val Acc: 0.9858\n",
      "Epoch [16/20] | Train Loss: 0.0218 | Train Acc: 0.9923 | Val Loss: 0.0415 | Val Acc: 0.9872\n",
      "Epoch [17/20] | Train Loss: 0.0536 | Train Acc: 0.9808 | Val Loss: 0.0366 | Val Acc: 0.9879\n",
      "Parada temprana en la √©poca 17\n",
      "üèÉ View run arq_3_EfficientNetB0_finetune at: http://3.89.116.159:8050/#/experiments/1/runs/c799f35d7eb945b6b4b0906b108cb789\n",
      "üß™ View experiment at: http://3.89.116.159:8050/#/experiments/1\n",
      "Run registrado en MLflow\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Entrenamiento con MLflow\n",
    "# =========================\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model_wts = copy.deepcopy(model_3.state_dict())\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# (Opcional) nombres de clases\n",
    "class_names = None\n",
    "try:\n",
    "    class_names = val_dataset.classes\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Conteo de par√°metros entrenables\n",
    "trainable_params = sum(p.numel() for p in model_3.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model_3.parameters())\n",
    "\n",
    "with mlflow.start_run(run_name=\"arq_3_EfficientNetB0_finetune\"):\n",
    "    # Tags √∫tiles para comparar modelos en MLflow\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"MRI Tumor Classification\",\n",
    "        \"model_arch\": \"efficientnet_b0_finetune\",\n",
    "        \"framework\": \"pytorch\",\n",
    "    })\n",
    "\n",
    "    # Par√°metros (ajusta/a√±ade seg√∫n tu caso)\n",
    "    mlflow.log_params({\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"patience\": patience,\n",
    "        \"lr\": optimizer.param_groups[0].get(\"lr\", None),\n",
    "        \"batch_size\": getattr(train_data_load, \"batch_size\", None),\n",
    "        \"img_size\": locals().get(\"img_size\", None),\n",
    "        \"val_split\": locals().get(\"val_split\", None),\n",
    "        \"seed\": locals().get(\"seed\", None),\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"total_params\": total_params,\n",
    "    })\n",
    "\n",
    "    # Guardar arquitectura como artefacto\n",
    "    arch_path = ARTIFACT_DIR / \"arq_3_EfficientNetB0_finetune_model_arch.txt\"\n",
    "    arch_path.write_text(str(model_3), encoding=\"utf-8\")\n",
    "    mlflow.log_artifact(str(arch_path))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model_3, train_data_load, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model_3, val_data_load, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Log de m√©tricas por √©poca (clave: step=epoch)\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"train_acc\": float(train_acc),\n",
    "            \"val_acc\": float(val_acc),\n",
    "        }, step=epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "              f'| Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} '\n",
    "              f'| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Guardar mejor modelo\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model_3.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model_3.state_dict(), 'best_model_effi_t.pth')\n",
    "            mlflow.log_metric(\"best_val_loss\", float(best_val_loss), step=epoch)\n",
    "            print(f\"Mejor modelo guardado en la √©poca {epoch+1} con p√©rdida de validaci√≥n {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Parada temprana en la √©poca {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Cargar el mejor modelo al final\n",
    "    model_3.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Curvas como artefacto\n",
    "    prefix = \"arq_3_EfficientNetB0_finetune\"\n",
    "    log_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, prefix)\n",
    "\n",
    "    # Log del checkpoint final (mejor)\n",
    "    if os.path.exists('best_model_effi_t.pth'):\n",
    "        mlflow.log_artifact('best_model_effi_t.pth')\n",
    "\n",
    "    # Evaluaci√≥n final + artefactos (reporte + matriz confusi√≥n)\n",
    "    _ = evaluate_and_log(model_3, val_data_load, device, prefix=prefix, class_names=class_names)\n",
    "\n",
    "print(\"Run registrado en MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6cbd64c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1771473362525,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "f6cbd64c",
    "outputId": "df1271f7-311f-4119-8304-11ff1f57edda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar los pesos del mejor modelo entrenado\n",
    "model_3.load_state_dict(torch.load('best_model_effi_t.pth', map_location=device))\n",
    "\n",
    "# Enviar a dispositivo y poner en modo evaluaci√≥n\n",
    "model_3 = model_3.to(device)\n",
    "model_3.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceff620",
   "metadata": {
    "id": "0ceff620"
   },
   "source": [
    "### Reporte de clasificaci√≥n arquitectura 3: EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e2365024",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6825,
     "status": "ok",
     "timestamp": 1771473369351,
     "user": {
      "displayName": "juan pablo cespedes ortiz",
      "userId": "15632312775783045046"
     },
     "user_tz": 300
    },
    "id": "e2365024",
    "outputId": "cf98220a-6a8e-4a46-fa66-c97732ee0dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       324\n",
      "     healthy       1.00      0.99      1.00       400\n",
      "  meningioma       0.99      0.99      0.99       329\n",
      "   pituitary       0.99      0.99      0.99       352\n",
      "\n",
      "    accuracy                           0.99      1405\n",
      "   macro avg       0.99      0.99      0.99      1405\n",
      "weighted avg       0.99      0.99      0.99      1405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener todas las predicciones y etiquetas verdaderas\n",
    "y_true_3 = []\n",
    "y_pred_3 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_data_load:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_3(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true_3.extend(labels.cpu().numpy())\n",
    "        y_pred_3.extend(preds.cpu().numpy())\n",
    "\n",
    "# Reporte detallado\n",
    "print(classification_report(y_true_3, y_pred_3, target_names=val_dataset.classes))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
